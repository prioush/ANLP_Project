{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33pIHV-N9d3"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "66PffmQSOAzy"
      },
      "outputs": [],
      "source": [
        "!pip install datasets keybert transformers kagglehub bertopic --quiet\n",
        "!pip install -q keybert sentence-transformers bertopic kagglehub tqdm wordcloud\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxA4PE_lOGrZ"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gSTddJBwOIn-"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import re\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# Third-party libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import umap\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "\n",
        "# NLP and Transformers\n",
        "import datasets\n",
        "from kagglehub import dataset_download\n",
        "from bertopic import BERTopic\n",
        "from keybert import KeyBERT\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcI_SKhwc2XX",
        "outputId": "39797a8a-59ed-4e3c-df8d-35ffeab5047b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/Colab Notebooks/ANLP_Project\"\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eT_fiRaOLxl"
      },
      "source": [
        "Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9qKdsNfRLth1"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "raw_metadata_path = os.path.join(PROJECT_DIR, \"metadata.csv\")\n",
        "processed_metadata_path = os.path.join(PROJECT_DIR, \"processed_cord19.csv\")\n",
        "essential_cols_path = os.path.join(PROJECT_DIR, \"cord19_essential.csv\")\n",
        "keywords_cache_path = os.path.join(PROJECT_DIR, \"doc_keywords.pkl\")\n",
        "kaggle_meta_path = os.path.join(PROJECT_DIR, \"kaggle_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKIrbSdAYVzk",
        "outputId": "22ba14f7-59ef-4e01-d54b-7920ce0bd200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Raw metadata file already exists.\n"
          ]
        }
      ],
      "source": [
        "# Download if not already present\n",
        "if not os.path.exists(raw_metadata_path):\n",
        "    print(\"Downloading CORD-19 metadata...\")\n",
        "    !wget -q https://ai2-semanticscholar-cord-19.s3.us-west-2.amazonaws.com/latest/metadata.csv -O \"{raw_metadata_path}\"\n",
        "else:\n",
        "    print(\"✅ Raw metadata file already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO_XRGXrPYDw",
        "outputId": "c0b9e549-2972-436e-e25b-39168290ed35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed metadata already exists.\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Process metadata if missing\n",
        "if not os.path.exists(processed_metadata_path):\n",
        "    print(\"🧹 Cleaning and saving processed metadata...\")\n",
        "    cord19_df = pd.read_csv(raw_metadata_path, low_memory=False)\n",
        "    cord19_df = cord19_df.drop_duplicates(subset=[\"cord_uid\"])\n",
        "    cord19_df.to_csv(processed_metadata_path, index=False)\n",
        "else:\n",
        "    print(\"✅ Processed metadata already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PViOn7UY1o5",
        "outputId": "3e4b64c4-1b7c-42d0-911a-21f905f11dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3782eee3c66e>:3: DtypeWarning: Columns (6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  cord19_df = pd.read_csv(essential_cols_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded essential columns from cache.\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Filter to essential columns\n",
        "if os.path.exists(essential_cols_path):\n",
        "    cord19_df = pd.read_csv(essential_cols_path)\n",
        "    print(\"✅ Loaded essential columns from cache.\")\n",
        "else:\n",
        "    full_df = pd.read_csv(processed_metadata_path, low_memory=False)\n",
        "    cols = [\n",
        "        \"cord_uid\", \"title\", \"authors\", \"abstract\", \"publish_time\",\n",
        "        \"journal\", \"doi\", \"url\", \"pdf_json_files\", \"pmc_json_files\"\n",
        "    ]\n",
        "    cord19_df = full_df[cols]\n",
        "    cord19_df.to_csv(essential_cols_path, index=False)\n",
        "    print(\"✅ Filtered and saved essential columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "gqwC5gMJq70z",
        "outputId": "6425d4a1-6b5e-4c32-e399-e59823324089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    OBJECTIVE: This retrospective chart review des...\n",
              "1    Inflammatory diseases of the respiratory tract...\n",
              "2    Surfactant protein-D (SP-D) participates in th...\n",
              "3    Endothelin-1 (ET-1) is a 21 amino acid peptide...\n",
              "4    Respiratory syncytial virus (RSV) and pneumoni...\n",
              "Name: abstract, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "cord19_df[\"abstract\"].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpNf8tSjTQ25"
      },
      "source": [
        "# Load googleai/cord19 metadata mappings from Kaggle (links papers to external datasets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5zPxb2XpTEIU"
      },
      "outputs": [],
      "source": [
        "!pip install -q kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qH8HmExRTF_6"
      },
      "outputs": [],
      "source": [
        "from kagglehub import dataset_download\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KYg2kA9wS7kX"
      },
      "outputs": [],
      "source": [
        "# Define where you want to cache the Kaggle metadata file\n",
        "#kaggle_meta_path = os.path.join(PROJECT_DIR, \"kaggle_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "u7lXxoGRS8Vi",
        "outputId": "22797c40-c17c-40dd-cd22-382264b1d369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Kaggle metadata from cache.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cord_uid                                          paper_url  \\\n",
              "0  rmzpiyqj  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...   \n",
              "1  h7g5ecc0  http://europepmc.org/articles/pmc4052367?pdf=r...   \n",
              "2  3uvlmww0  https://jvi.asm.org/content/jvi/88/17/10228.fu...   \n",
              "3  xzps65et            https://doi.org/10.14745/ccdr.v45i04a01   \n",
              "4  a6p8te8q  https://jvi.asm.org/content/jvi/79/6/3370.full...   \n",
              "\n",
              "                                         paper_title  \\\n",
              "0  Nipah virus: epidemiology, pathology, immunobi...   \n",
              "1  Novel approaches and challenges to treatment o...   \n",
              "2  Verdinexor, a Novel Selective Inhibitor of Nuc...   \n",
              "3  Climate change and infectious diseases: What c...   \n",
              "4  Increased Epitope-Specific CD8(+) T Cells Prev...   \n",
              "\n",
              "                                         dataset_url  \\\n",
              "0  https://data.csiro.au/dap/landingpage?pid=csir...   \n",
              "1  https://datamed.org/display-item.php?repositor...   \n",
              "2  https://datamed.org/display-item.php?repositor...   \n",
              "3  https://search.datacite.org/works/10.5065/d6sj...   \n",
              "4  http://www.immunedata.org/display-item.php?rep...   \n",
              "\n",
              "                                        dataset_name alternate_name  \\\n",
              "0  Nature of exposure drives transmission of Nipa...            NaN   \n",
              "1  Key Role of T cell Defects in Age-Related Vuln...            NaN   \n",
              "2        MicroRNA Regulation of Human Protease Genes            NaN   \n",
              "3                              The NA-CORDEX dataset            NaN   \n",
              "4                                    CMV CD8 T Cells            NaN   \n",
              "\n",
              "                                         description  \\\n",
              "0  [\"RT-PCR data of comparative viral loads/ tiss...   \n",
              "1  [\"In a mouse model of age-related vulnerabilit...   \n",
              "2  the human protease genes required for influenz...   \n",
              "3  [\"The NA-CORDEX data archive contains output f...   \n",
              "4  [\"We present human T cell responses in multipl...   \n",
              "\n",
              "                                         author_list last_updated  \\\n",
              "0  Bronwyn Clayton; Deborah Middleton; Rachel Ark...         2016   \n",
              "1                                                NaN   2019-05-06   \n",
              "2                                                NaN   2011-10-13   \n",
              "3  Linda Mearns; Seth McGinnis; Daniel Korytina; ...         2017   \n",
              "4                                                NaN   2018-09-17   \n",
              "\n",
              "                                             license source_organization  \\\n",
              "0  [{\"url\":\"https://confluence.csiro.au/display/d...               CSIRO   \n",
              "1                                                NaN                 NaN   \n",
              "2                                                NaN                 NaN   \n",
              "3         [{\"url\":\"http://na-cordex.org/terms-use\"}]           UCAR/NCAR   \n",
              "4                                                NaN                 NaN   \n",
              "\n",
              "                        doi compact_identifier data_download  \n",
              "0  10.4225/08/56806AAEAD713                NaN           NaN  \n",
              "1                       NaN                NaN           NaN  \n",
              "2                       NaN                NaN           NaN  \n",
              "3          10.5065/d6sj1jch                NaN           NaN  \n",
              "4                       NaN                NaN           NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa70997a-8db0-4ad5-86a2-087a8133b9aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cord_uid</th>\n",
              "      <th>paper_url</th>\n",
              "      <th>paper_title</th>\n",
              "      <th>dataset_url</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>alternate_name</th>\n",
              "      <th>description</th>\n",
              "      <th>author_list</th>\n",
              "      <th>last_updated</th>\n",
              "      <th>license</th>\n",
              "      <th>source_organization</th>\n",
              "      <th>doi</th>\n",
              "      <th>compact_identifier</th>\n",
              "      <th>data_download</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rmzpiyqj</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "      <td>Nipah virus: epidemiology, pathology, immunobi...</td>\n",
              "      <td>https://data.csiro.au/dap/landingpage?pid=csir...</td>\n",
              "      <td>Nature of exposure drives transmission of Nipa...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"RT-PCR data of comparative viral loads/ tiss...</td>\n",
              "      <td>Bronwyn Clayton; Deborah Middleton; Rachel Ark...</td>\n",
              "      <td>2016</td>\n",
              "      <td>[{\"url\":\"https://confluence.csiro.au/display/d...</td>\n",
              "      <td>CSIRO</td>\n",
              "      <td>10.4225/08/56806AAEAD713</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>h7g5ecc0</td>\n",
              "      <td>http://europepmc.org/articles/pmc4052367?pdf=r...</td>\n",
              "      <td>Novel approaches and challenges to treatment o...</td>\n",
              "      <td>https://datamed.org/display-item.php?repositor...</td>\n",
              "      <td>Key Role of T cell Defects in Age-Related Vuln...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"In a mouse model of age-related vulnerabilit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-05-06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3uvlmww0</td>\n",
              "      <td>https://jvi.asm.org/content/jvi/88/17/10228.fu...</td>\n",
              "      <td>Verdinexor, a Novel Selective Inhibitor of Nuc...</td>\n",
              "      <td>https://datamed.org/display-item.php?repositor...</td>\n",
              "      <td>MicroRNA Regulation of Human Protease Genes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>the human protease genes required for influenz...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xzps65et</td>\n",
              "      <td>https://doi.org/10.14745/ccdr.v45i04a01</td>\n",
              "      <td>Climate change and infectious diseases: What c...</td>\n",
              "      <td>https://search.datacite.org/works/10.5065/d6sj...</td>\n",
              "      <td>The NA-CORDEX dataset</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"The NA-CORDEX data archive contains output f...</td>\n",
              "      <td>Linda Mearns; Seth McGinnis; Daniel Korytina; ...</td>\n",
              "      <td>2017</td>\n",
              "      <td>[{\"url\":\"http://na-cordex.org/terms-use\"}]</td>\n",
              "      <td>UCAR/NCAR</td>\n",
              "      <td>10.5065/d6sj1jch</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a6p8te8q</td>\n",
              "      <td>https://jvi.asm.org/content/jvi/79/6/3370.full...</td>\n",
              "      <td>Increased Epitope-Specific CD8(+) T Cells Prev...</td>\n",
              "      <td>http://www.immunedata.org/display-item.php?rep...</td>\n",
              "      <td>CMV CD8 T Cells</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"We present human T cell responses in multipl...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-09-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa70997a-8db0-4ad5-86a2-087a8133b9aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa70997a-8db0-4ad5-86a2-087a8133b9aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa70997a-8db0-4ad5-86a2-087a8133b9aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a13fcb2-d0d9-49a6-a3c9-9f0c54f38cc4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a13fcb2-d0d9-49a6-a3c9-9f0c54f38cc4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a13fcb2-d0d9-49a6-a3c9-9f0c54f38cc4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_meta_cord19",
              "summary": "{\n  \"name\": \"df_meta_cord19\",\n  \"rows\": 16070,\n  \"fields\": [\n    {\n      \"column\": \"cord_uid\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4024,\n        \"samples\": [\n          \"exkm0o6p\",\n          \"aprh5q3x\",\n          \"ojp6p31u\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4024,\n        \"samples\": [\n          \"https://jvi.asm.org/content/jvi/84/15/7880.full.pdf\",\n          \"https://doi.org/10.1016/j.jaci.2018.02.035\",\n          \"https://jvi.asm.org/content/jvi/87/21/11579.full.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4024,\n        \"samples\": [\n          \"The Proteasome Inhibitor Velcade Enhances rather than Reduces Disease in Mouse Hepatitis Coronavirus-Infected Mice\",\n          \"Chronic obstructive pulmonary disease subpopulations and phenotyping\",\n          \"Transmissible Gastroenteritis Coronavirus Genome Packaging Signal Is Located at the 5\\u2032 End of the Genome and Promotes Viral RNA Incorporation into Virions in a Replication-Independent Process\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11731,\n        \"samples\": [\n          \"https://crrd.mcw.edu/rgdweb/report/gene/main.html?id=14289119\",\n          \"https://rgd.mcw.edu/rgdweb/report/gene/main.html?id=1311528\",\n          \"https://reactome.org/content/detail/R-HSA-163200\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8778,\n        \"samples\": [\n          \"pou6f2\",\n          \"dctn3\",\n          \"RNA Viruses in Hymenopteran Pollinators: Evidence of Inter-Taxa Virus Transmission via Pollen and Potential Impact on Non-Apis Hymenopteran Species\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alternate_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 72,\n        \"samples\": [\n          \"[\\\"SCR_012983, (Virus Pathogen Resource (ViPR), RRID:SCR_012983), ViPR, ViPR, Virus Pathogen Resource\\\"]\",\n          \"[\\\"SCR_008111, (Biochemical Pathways database, RRID:SCR_008111), Biopath\\\"]\",\n          \"[\\\"SCR_002102, (ASPicDB, RRID:SCR_002102), ASPicDB, ASPicDB - A Database tool for alternative splicing analysis, Alternative Splicing Prediction Data Base\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10236,\n        \"samples\": [\n          \"[\\\"A synergistic combination of two next-generation sequencing platforms with a detailed comparative BAC physical contig map provided a cost-effective assembly of the genome sequence of the domestic turkey (Meleagris gallopavo). Heterozygosity of the sequenced source genome allowed discovery of more than 600,000 high quality single nucleotide variants. Despite this heterozygosity, the current genome assembly (\\u223c1.1 Gb) includes 917 Mb of sequence assigned to specific turkey chromosomes. Annotation identified nearly 16,000 genes, with 15,093 recognized as protein coding and 611 as non-coding RNA genes. Comparative analysis of the turkey, chicken, and zebra finch genomes, and comparing avian to mammalian species, supports the characteristic stability of avian genomes and identifies genes unique to the avian lineage. Clear differences are seen in number and variety of genes of the avian immune system where expansions and novel genes are less frequent than examples of gene loss. The turkey genome sequence provides resources to further understand the evolution of vertebrate genomes and genetic variation underlying economically important quantitative traits in poultry. This integrated approach may be a model for providing both gene and chromosome level assemblies of other species with agricultural, ecological, and evolutionary interest.\\\"]\",\n          \"Exhibits RIG-I binding activity and molecular function regulator. Involved in choline transport and negative regulation of RIG-I signaling pathway. Localizes to the cytosol and nucleoplasm. Colocalizes with the Golgi apparatus. The protein encoded by this gene belongs to the SEC14 cytosolic factor family. It has similarity to yeast SEC14 and to Japanese flying squid RALBP which suggests a possible role of the gene product in an intracellular transport system. Multiple alternatively spliced transcript variants have been found for this gene; some variants represent read-through transcripts that include exons from the upstream gene C17orf86. [provided by RefSeq, Feb 2011]\",\n          \"[\\\"ASSOCIATED WITH Transplant Rejection (ortholog); type 1 diabetes mellitus (ortholog); FOUND IN cytosol (inferred); nucleoplasm (inferred); plasma membrane (inferred)\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_list\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4036,\n        \"samples\": [\n          \"Dalia A. Conde; Fernando Colchero; Markus Gusset; Paul Pearce-Kelly; Onnie Byers; Nate Flesness; Robert K. Browne; Owen R. Jones\",\n          \"Jonathan S. Towner; Brian R. Amman; Tara K. Sealy; Serena A. Reeder Carroll; James A. Comer; Alan Kemp; Robert Swanepoel; Christopher D. Paddock; Stephen Balinandi; Marina L. Khristova; Pierre B. H. Formenty; Cesar G. Albarino; David M. Miller; Zachary D. Reed; John T. Kayiwa; James N. Mills; Deborah L. Cannon; Patricia W. Greer; Emmanuel Byaruhanga; Eileen C. Farnon; Patrick Atimnedi; Samuel Okware; Edward Katongole-Mbidde; Robert Downing; Jordan W. Tappero; Sherif R. Zaki; Thomas G. Ksiazek; Stuart T. Nichol; Pierre E. Rollin\",\n          \"Yutaka Takebe; Carrie J. Saucedo; Garry Lund; Rie Uenishi; Saiki Hase; Takayo Tsuchiura; Norman Kneteman; Koreen Ramessar; D. Lorne J. Tyrrell; Masayuki Shirakura; Takaji Wakita; James B. McMahon; Barry R. O'Keefe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_updated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1362,\n        \"samples\": [\n          \"2013-01-28\",\n          \"2010-06-01\",\n          \"2019-01-18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"license\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"[{\\\"text\\\":\\\"<span style='font-family: Verdana, Helvetica, sans-serif; font-size: 12px; background-color: rgb(255, 255, 255);'><b>Aviso Legal</b></span><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'>Este aviso legal recoge las condiciones generales que rigen el acceso y el uso de los datos. El uso del sitio web implica la expresa y plena aceptaci\\u00f3n de las presentes condiciones generales en la versi\\u00f3n publicada en el momento en que el usuario acceda al mismo, sin perjuicio de las condiciones particulares que pudieran aplicarse a algunos de los contenidos o servicios concretos del sitio web.<br />A los efectos del presente documento se entiende por \\u201cagente reutilizador\\u201d toda persona, f\\u00edsica o jur\\u00eddica que reutilice informaci\\u00f3n del sector p\\u00fablico, ya sea para fines comerciales o no comerciales.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Obligatoriedad de las condiciones generales.</span><br />Las presentes condiciones generales, disponibles con car\\u00e1cter permanente vincular\\u00e1n a cualquier agente reutilizador por el mero hecho de hacer uso de los documentos sometidos a ellas.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Autorizaci\\u00f3n de reutilizaci\\u00f3n y cesi\\u00f3n no exclusiva de derechos de propiedad intelectual.</span><br />Las presentes condiciones generales permiten la reutilizaci\\u00f3n de los documentos sometidos a ellas para fines comerciales y no comerciales. Se entiende por reutilizaci\\u00f3n el uso de documentos que obran en poder de los \\u00f3rganos de la Administraci\\u00f3n, sobre reutilizaci\\u00f3n de la informaci\\u00f3n del sector p\\u00fablico con fines comerciales o no comerciales, siempre que dicho uso no constituya una actividad administrativa p\\u00fablica. La reutilizaci\\u00f3n autorizada incluye, a modo ilustrativo, actividades como la copia, difusi\\u00f3n, modificaci\\u00f3n, adaptaci\\u00f3n, extracci\\u00f3n, reordenaci\\u00f3n y combinaci\\u00f3n de la informaci\\u00f3n.<br />El concepto de documento es el establecido en el apartado 2 del art\\u00edculo 3 de la Ley 37/2007, de 16 de noviembre, sobre reutilizaci\\u00f3n de la informaci\\u00f3n del sector p\\u00fablico, por lo que comprende toda informaci\\u00f3n cualquiera que sea su soporte material o electr\\u00f3nico as\\u00ed como su forma de expresi\\u00f3n gr\\u00e1fica, sonora o en imagen utilizada, incluyendo, en consecuencia, tambi\\u00e9n los datos en sus niveles m\\u00e1s desagregados o \\u201cen bruto\\u201d.<br />Esta autorizaci\\u00f3n conlleva, asimismo, la cesi\\u00f3n gratuita y no exclusiva de los derechos de propiedad intelectual, en su caso, correspondientes a tales documentos, autoriz\\u00e1ndose la realizaci\\u00f3n de actividades de reproducci\\u00f3n, distribuci\\u00f3n, comunicaci\\u00f3n p\\u00fablica o transformaci\\u00f3n, necesarias para desarrollar la actividad de reutilizaci\\u00f3n autorizada, en cualquier modalidad y bajo cualquier formato, para todo el mundo y por el plazo m\\u00e1ximo permitido por la Ley.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Condiciones generales para la reutilizaci\\u00f3n.</span><br />Son de aplicaci\\u00f3n las siguientes condiciones generales para la reutilizaci\\u00f3n de los documentos sometidos a ellas:</p><ol><li>Est\\u00e1 prohibido desnaturalizar el sentido de la informaci\\u00f3n.</li><li>Debe citarse la fuente de los documentos objeto de la reutilizaci\\u00f3n.</li><li>Debe mencionarse la fecha de la \\u00faltima actualizaci\\u00f3n de los documentos objeto de la reutilizaci\\u00f3n, siempre cuando estuviera incluida en el documento original.</li><li>No se podr\\u00e1 indicar, insinuar o sugerir que los titulares de la informaci\\u00f3n reutilizada participan, patrocinan o apoyan la reutilizaci\\u00f3n que se lleve a cabo con ella.</li><li>Deben conservarse, no alterarse ni suprimirse los metadatos sobre la fecha de actualizaci\\u00f3n y las condiciones de reutilizaci\\u00f3n aplicables incluidos, en su caso, en el documento puesto a disposici\\u00f3n para su reutilizaci\\u00f3n.</li></ol><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Exclusi\\u00f3n de responsabilidad.</span><br />La utilizaci\\u00f3n de los conjuntos de datos se realizar\\u00e1 por parte de los usuarios o agentes de la reutilizaci\\u00f3n bajo su propia cuenta y riesgo, correspondi\\u00e9ndoles en exclusiva a ellos responder frente a terceros por da\\u00f1os que pudieran derivarse de ella. El Cabildo de La Palma no ser\\u00e1 responsable del uso que de su informaci\\u00f3n hagan los agentes reutilizadores ni tampoco de los da\\u00f1os sufridos o p\\u00e9rdidas econ\\u00f3micas que, de forma directa o indirecta, produzcan o puedan producir perjuicios econ\\u00f3micos, materiales o sobre datos, provocados por el uso de la informaci\\u00f3n reutilizada. El Cabildo de La Palma no garantiza la continuidad en la puesta a disposici\\u00f3n de los documentos reutilizables, ni en contenido ni en forma, ni asume responsabilidades por cualquier error u omisi\\u00f3n contenido en ellos.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Responsabilidad del agente reutilizador.</span><br />El agente reutilizador se halla sometido a la normativa aplicable en materia de reutilizaci\\u00f3n de la informaci\\u00f3n del sector p\\u00fablico, incluyendo el r\\u00e9gimen sancionador previsto en el art\\u00edculo 11 de la Ley 37/2007, de 16 de noviembre, sobre reutilizaci\\u00f3n de la informaci\\u00f3n del sector p\\u00fablico.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Protecci\\u00f3n de datos de car\\u00e1cter personal.</span><br />La web www.opendatalapalma.es est\\u00e1 comprometida con el respeto a la intimidad del usuario. El Cabildo de La Palma , es el responsable del fichero de datos generado con los datos de car\\u00e1cter personal suministrados por los usuarios del sitio web.<br />De acuerdo con lo dispuesto en la Ley Org\\u00e1nica 15/1999, de 13 de diciembre, de Protecci\\u00f3n de Datos de Car\\u00e1cter Personal, el Cabildo de La Palma se compromete al cumplimiento de su obligaci\\u00f3n de secreto con respecto a los datos de car\\u00e1cter personal y al deber de tratarlos con confidencialidad. A estos efectos, adoptar\\u00e1 las medidas necesarias para evitar su alteraci\\u00f3n, p\\u00e9rdida, tratamiento o acceso no autorizado.</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Modificaciones.</span><br />Con el fin de mejorar las prestaciones del sitio web, el Cabildo de La Palma se reserva el derecho, en cualquier momento y sin previa notificaci\\u00f3n al usuario, a modificar ampliar o suspender temporalmente la presentaci\\u00f3n, configuraci\\u00f3n, especificaciones t\\u00e9cnicas y servicios del sitio web, de forma unilateral. Asimismo, se reserva el derecho a modificar en cualquier momento las presentes condiciones de uso as\\u00ed como cualesquiera otras condiciones particulares</p><p style='margin-top: 0px; margin-bottom: 1.71429em; padding: 0px; font-size: 0.875em; line-height: 1.71429em; color: rgb(77, 77, 77); font-family: Arial, Helvetica, San-Serif; background-color: rgb(255, 255, 255);'><span style='font-weight: 700;'>Hiperenlaces.</span><br />Los hiperenlaces contenidos en el sitio web pueden dirigir a p\\u00e1ginas web de terceros. El Cabildo de La Palma no asume ninguna responsabilidad por el contenido, informaciones o servicios que pudieran aparecer en dichos sitios, que tendr\\u00e1n exclusivamente car\\u00e1cter informativo y que en ning\\u00fan caso implican relaci\\u00f3n alguna con los contenidos o titulares de los sitios donde se encuentren.</p>\\\"}]\",\n          \"[{\\\"url\\\":\\\"http://fantom.gsc.riken.jp/4/download/\\\"}]\",\n          \"[{\\\"url\\\":\\\"https://confluence.csiro.au/display/daphelp/CSIRO+Data+Licence\\\"}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_organization\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 151,\n        \"samples\": [\n          \"The Food and Environment Research Agency\",\n          \"PLOS Neglected Tropical Diseases\",\n          \"Natural Resources Canada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doi\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3982,\n        \"samples\": [\n          \"10.1172/jci.insight.126543\",\n          \"10.1371/journal.ppat.1003605\",\n          \"10.1371/journal.pone.0000279\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"compact_identifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1606,\n        \"samples\": [\n          \"[\\\"HGNC:19080\\\"]\",\n          \"[\\\"ZFIN:ZDB-GENE-080204-45\\\"]\",\n          \"ZFIN:ZDB-GENE-040426-2289\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_download\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3795,\n        \"samples\": [\n          \"[{\\\"download_url\\\":\\\"https://ndownloader.figshare.com/files/354760\\\",\\\"file_format\\\":\\\"doc\\\",\\\"file_format_class\\\":\\\"CLASS_DOCUMENT\\\"}]\",\n          \"[{\\\"download_url\\\":\\\"https://ndownloader.figshare.com/files/11277818\\\",\\\"file_format\\\":\\\"tiff\\\",\\\"file_format_class\\\":\\\"CLASS_IMAGE\\\"},{\\\"download_url\\\":\\\"https://ndownloader.figshare.com/files/11277824\\\",\\\"file_format\\\":\\\"tiff\\\",\\\"file_format_class\\\":\\\"CLASS_IMAGE\\\"},{\\\"download_url\\\":\\\"https://ndownloader.figshare.com/files/11277821\\\",\\\"file_format\\\":\\\"tiff\\\",\\\"file_format_class\\\":\\\"CLASS_IMAGE\\\"}]\",\n          \"[{\\\"download_url\\\":\\\"https://plos.figshare.com/ndownloader/files/1635775\\\",\\\"file_format\\\":\\\"doc\\\",\\\"file_format_class\\\":\\\"CLASS_DOCUMENT\\\"}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Download if not already cached\n",
        "if os.path.exists(kaggle_meta_path):\n",
        "    df_meta_cord19 = pd.read_csv(kaggle_meta_path)\n",
        "    print(\"✅ Loaded Kaggle metadata from cache.\")\n",
        "else:\n",
        "    print(\"⬇️ Downloading Kaggle CORD-19 metadata...\")\n",
        "    path = dataset_download(handle=\"googleai/dataset-metadata-for-cord19\")\n",
        "    filename = os.listdir(path)[0]\n",
        "    source_file = os.path.join(path, filename)\n",
        "\n",
        "    shutil.copyfile(source_file, kaggle_meta_path)\n",
        "    df_meta_cord19 = pd.read_csv(kaggle_meta_path)\n",
        "    print(\"✅ Downloaded and cached Kaggle metadata.\")\n",
        "\n",
        "# Preview\n",
        "df_meta_cord19.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDPgEzJUOc3g"
      },
      "source": [
        "#Use of BERT for filtering the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yelIt7eGlH2N",
        "outputId": "1f2d6aa2-f4cd-4ffc-f548-c145ebf9777f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic[visualization] in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "\u001b[33mWARNING: bertopic 0.17.0 does not provide the extra 'visualization'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (4.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (0.5.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic[visualization]) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic[visualization]) (24.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic[visualization]) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (4.52.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.31.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (4.13.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.32.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic[visualization]) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[visualization]) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic[visualization]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kdrdz5Cjyzw"
      },
      "source": [
        "Filtering with KeyBERT, Semantic Similarity, and BERTopic ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "mQWqUZtcjzkk",
        "outputId": "4acb6458-4949-4467-fb13-3cb14e1bc865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 970836 entries, 0 to 970835\n",
            "Data columns (total 10 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   cord_uid        970836 non-null  object\n",
            " 1   title           970340 non-null  object\n",
            " 2   authors         948634 non-null  object\n",
            " 3   abstract        763499 non-null  object\n",
            " 4   publish_time    969037 non-null  object\n",
            " 5   journal         887275 non-null  object\n",
            " 6   doi             654783 non-null  object\n",
            " 7   url             684925 non-null  object\n",
            " 8   pdf_json_files  372888 non-null  object\n",
            " 9   pmc_json_files  315041 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 74.1+ MB\n",
            "\n",
            "🧱 Columns: ['cord_uid', 'title', 'authors', 'abstract', 'publish_time', 'journal', 'doi', 'url', 'pdf_json_files', 'pmc_json_files']\n",
            "\n",
            "🔍 Sample Rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        cord_uid                                              title  \\\n",
              "702123  g0lcoedm  Positive rates predict death rates of Covid-19...   \n",
              "131254  gszsv5cj  Artificial Intelligence-Based Image Enhancemen...   \n",
              "28910   nwvsubtj  rs2671655 single nucleotide polymorphism modul...   \n",
              "\n",
              "                                                  authors  \\\n",
              "702123                            Mimkes, J.; Janssen, R.   \n",
              "131254  Liu, Juan; Malekzadeh, Masoud; Mirian, Niloufa...   \n",
              "28910   Shin, Cheol Min; Park, Kyungtaek; Kim, Nayoung...   \n",
              "\n",
              "                                                 abstract publish_time  \\\n",
              "702123  In the Covid-19-pandemic, the numbers of decea...   2020-11-28   \n",
              "131254  High noise and low spatial resolution are two ...   2021-10-01   \n",
              "28910   OBJECTIVE: To identify genetic variations whic...   2022-03-24   \n",
              "\n",
              "               journal                          doi  \\\n",
              "702123             NaN  10.1101/2020.11.24.20237842   \n",
              "131254     PET clinics   10.1016/j.cpet.2021.06.005   \n",
              "28910   Gastric Cancer   10.1007/s10120-022-01285-x   \n",
              "\n",
              "                                                      url  \\\n",
              "702123  http://medrxiv.org/cgi/content/short/2020.11.2...   \n",
              "131254  https://doi.org/10.1016/j.cpet.2021.06.005; ht...   \n",
              "28910   https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8...   \n",
              "\n",
              "                                           pdf_json_files  \\\n",
              "702123  document_parses/pdf_json/798a028b2bb8792c2dbf6...   \n",
              "131254                                                NaN   \n",
              "28910   document_parses/pdf_json/8bf48aa3c3978f3a235f9...   \n",
              "\n",
              "                                      pmc_json_files  \n",
              "702123                                           NaN  \n",
              "131254                                           NaN  \n",
              "28910   document_parses/pmc_json/PMC8943788.xml.json  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de14b514-30b7-411f-9b9c-17d66fcc9f69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cord_uid</th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>journal</th>\n",
              "      <th>doi</th>\n",
              "      <th>url</th>\n",
              "      <th>pdf_json_files</th>\n",
              "      <th>pmc_json_files</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>702123</th>\n",
              "      <td>g0lcoedm</td>\n",
              "      <td>Positive rates predict death rates of Covid-19...</td>\n",
              "      <td>Mimkes, J.; Janssen, R.</td>\n",
              "      <td>In the Covid-19-pandemic, the numbers of decea...</td>\n",
              "      <td>2020-11-28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1101/2020.11.24.20237842</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.11.2...</td>\n",
              "      <td>document_parses/pdf_json/798a028b2bb8792c2dbf6...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131254</th>\n",
              "      <td>gszsv5cj</td>\n",
              "      <td>Artificial Intelligence-Based Image Enhancemen...</td>\n",
              "      <td>Liu, Juan; Malekzadeh, Masoud; Mirian, Niloufa...</td>\n",
              "      <td>High noise and low spatial resolution are two ...</td>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>PET clinics</td>\n",
              "      <td>10.1016/j.cpet.2021.06.005</td>\n",
              "      <td>https://doi.org/10.1016/j.cpet.2021.06.005; ht...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28910</th>\n",
              "      <td>nwvsubtj</td>\n",
              "      <td>rs2671655 single nucleotide polymorphism modul...</td>\n",
              "      <td>Shin, Cheol Min; Park, Kyungtaek; Kim, Nayoung...</td>\n",
              "      <td>OBJECTIVE: To identify genetic variations whic...</td>\n",
              "      <td>2022-03-24</td>\n",
              "      <td>Gastric Cancer</td>\n",
              "      <td>10.1007/s10120-022-01285-x</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8...</td>\n",
              "      <td>document_parses/pdf_json/8bf48aa3c3978f3a235f9...</td>\n",
              "      <td>document_parses/pmc_json/PMC8943788.xml.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de14b514-30b7-411f-9b9c-17d66fcc9f69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de14b514-30b7-411f-9b9c-17d66fcc9f69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de14b514-30b7-411f-9b9c-17d66fcc9f69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a8b5d627-0981-420c-8f56-270d8cfe7e8a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8b5d627-0981-420c-8f56-270d8cfe7e8a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a8b5d627-0981-420c-8f56-270d8cfe7e8a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# 📊 Step 1: Dataset Overview\n",
        "# -----------------------------\n",
        "print(\"📄 Dataset Info:\")\n",
        "cord19_df.info()\n",
        "\n",
        "print(\"\\n🧱 Columns:\", list(cord19_df.columns))\n",
        "print(\"\\n🔍 Sample Rows:\")\n",
        "display(cord19_df.sample(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Nuc4gskBbl",
        "outputId": "de41775d-8c10-47b6-aa2f-11a7187294e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📘 Smoking keyword frequencies in column: 'title'\n",
            "  🔹 smoking: 1122\n",
            "  🔹 tobacco: 773\n",
            "  🔹 nicotine: 213\n",
            "  🔹 cigarette: 592\n",
            "  🔹 e-cigarette: 262\n",
            "  🔹 vaping: 264\n",
            "  🔹 lung cancer: 1705\n",
            "  🔹 chronic bronchitis: 23\n",
            "  🔹 secondhand smoke: 9\n",
            "  🔹 nicotine dependence: 16\n",
            "  🔹 smoke exposure: 41\n",
            "  🔹 smoker: 265\n",
            "  🔹 hookah: 17\n",
            "\n",
            "📘 Smoking keyword frequencies in column: 'abstract'\n",
            "  🔹 smoking: 5870\n",
            "  🔹 tobacco: 2140\n",
            "  🔹 nicotine: 669\n",
            "  🔹 cigarette: 1564\n",
            "  🔹 e-cigarette: 518\n",
            "  🔹 vaping: 432\n",
            "  🔹 lung cancer: 2799\n",
            "  🔹 chronic bronchitis: 98\n",
            "  🔹 secondhand smoke: 48\n",
            "  🔹 nicotine dependence: 94\n",
            "  🔹 smoke exposure: 144\n",
            "  🔹 smoker: 2270\n",
            "  🔹 hookah: 36\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# 🔍 Step 2: Smoking Keyword Exploration\n",
        "# -----------------------------\n",
        "SMOKING_KEYWORDS = [\n",
        "    \"smoking\", \"tobacco\", \"nicotine\", \"cigarette\", \"e-cigarette\",\n",
        "    \"vaping\", \"lung cancer\", \"chronic bronchitis\", \"secondhand smoke\",\n",
        "    \"nicotine dependence\", \"smoke exposure\", \"smoker\", \"hookah\"\n",
        "]\n",
        "\n",
        "text_columns = [\"title\", \"abstract\"]\n",
        "\n",
        "for col in text_columns:\n",
        "    if col in cord19_df.columns:\n",
        "        print(f\"\\n📘 Smoking keyword frequencies in column: '{col}'\")\n",
        "        for kw in SMOKING_KEYWORDS:\n",
        "            count = cord19_df[col].astype(str).str.contains(kw, case=False, na=False).sum()\n",
        "            if count > 0:\n",
        "                print(f\"  🔹 {kw}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kccwpedS-Nbb",
        "outputId": "f22664e2-8703-48f9-b080-06b2713fa7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.31.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zb2IuffiBSK-"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "SMOKING_KEYWORDS = [\n",
        "    \"smoking\", \"tobacco\", \"nicotine\", \"cigarette\", \"e-cigarette\",\n",
        "    \"vaping\", \"lung cancer\", \"chronic bronchitis\", \"secondhand smoke\",\n",
        "    \"nicotine dependence\", \"smoke exposure\", \"smoker\", \"hookah\"\n",
        "]\n",
        "\n",
        "COVID_KEYWORDS = ['covid', 'coronavirus', 'sars-cov-2', 'pandemic']\n",
        "ALL_KEYWORDS = SMOKING_KEYWORDS + COVID_KEYWORDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "hwrWpsdDBYu-",
        "outputId": "de2fe83d-eb3c-488c-8bb9-d9521115d362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded cached document keywords.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cord_uid                                           keywords\n",
              "0  ug7v899j  [infections bronchiolitis, cultures respirator...\n",
              "1  02tnwd4m  [diseases respiratory, diseases lung, respirat...\n",
              "2  ejv2xln0  [antigens sp, surfactant lipids, sp increased,...\n",
              "3  2b73a28n             [et 21, endothelin, inflammatory lung]\n",
              "4  9785vg6d  [display reverse, mucosal responses, transcrip..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4dd8274-391b-4dcd-af3a-dd7a1a1c6ad6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cord_uid</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>[infections bronchiolitis, cultures respirator...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>[diseases respiratory, diseases lung, respirat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>[antigens sp, surfactant lipids, sp increased,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>[et 21, endothelin, inflammatory lung]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>[display reverse, mucosal responses, transcrip...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4dd8274-391b-4dcd-af3a-dd7a1a1c6ad6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4dd8274-391b-4dcd-af3a-dd7a1a1c6ad6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4dd8274-391b-4dcd-af3a-dd7a1a1c6ad6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6595cafa-8275-4353-8032-3b17f86d6a77\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6595cafa-8275-4353-8032-3b17f86d6a77')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6595cafa-8275-4353-8032-3b17f86d6a77 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"cord19_df[['cord_uid', 'keywords']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"cord_uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"02tnwd4m\",\n          \"9785vg6d\",\n          \"ejv2xln0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from keybert import KeyBERT\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "keywords_cache_path = os.path.join(PROJECT_DIR, \"doc_keywords.pkl\")\n",
        "\n",
        "if os.path.exists(keywords_cache_path):\n",
        "    print(\"✅ Loaded cached document keywords.\")\n",
        "    with open(keywords_cache_path, \"rb\") as f:\n",
        "        doc_keywords = pickle.load(f)\n",
        "else:\n",
        "    print(\"🚀 Running KeyBERT keyword extraction...\")\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    kw_model = KeyBERT(model)\n",
        "\n",
        "    def chunk_text_simple(text, max_words=80, overlap=20):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "        for i in range(0, len(words), max_words - overlap):\n",
        "            chunk = \" \".join(words[i:i + max_words])\n",
        "            if len(chunk.split()) >= 10:\n",
        "                chunks.append(chunk)\n",
        "        return chunks\n",
        "\n",
        "    chunked_docs, doc_indices = [], []\n",
        "    for idx, text in cord19_df['abstract'].dropna().astype(str).items():\n",
        "        chunks = chunk_text_simple(text)\n",
        "        chunked_docs.extend(chunks)\n",
        "        doc_indices.extend([idx] * len(chunks))\n",
        "\n",
        "    chunked_docs = chunked_docs[:7000]\n",
        "    doc_indices = doc_indices[:7000]\n",
        "\n",
        "    keywords_list = kw_model.extract_keywords(\n",
        "        chunked_docs,\n",
        "        keyphrase_ngram_range=(1, 2),\n",
        "        stop_words='english',\n",
        "        use_mmr=True,\n",
        "        top_n=3\n",
        "    )\n",
        "\n",
        "    doc_keywords = defaultdict(set)\n",
        "    for doc_id, keywords in zip(doc_indices, keywords_list):\n",
        "        for kw, _ in keywords:\n",
        "            doc_keywords[doc_id].add(kw)\n",
        "\n",
        "    with open(keywords_cache_path, \"wb\") as f:\n",
        "        pickle.dump(doc_keywords, f)\n",
        "\n",
        "# Attach keywords to DataFrame\n",
        "cord19_df['keywords'] = cord19_df.index.map(lambda idx: list(doc_keywords.get(idx, [])))\n",
        "cord19_df[['cord_uid', 'keywords']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffV069hx9nZd"
      },
      "outputs": [],
      "source": [
        "def is_relevant(text):\n",
        "    return any(k in str(text).lower() for k in ALL_KEYWORDS)\n",
        "\n",
        "cord19_df['is_relevant'] = cord19_df['abstract'].apply(is_relevant)\n",
        "relevant_df = cord19_df[cord19_df['is_relevant'] & cord19_df['keywords'].notna()]\n",
        "keywords_flat = list(itertools.chain.from_iterable(relevant_df['keywords'].tolist()))\n",
        "keywords_text = \" \".join(keywords_flat)\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    width=1000, height=500,\n",
        "    background_color='white',\n",
        "    max_words=150,\n",
        "    collocations=False\n",
        ").generate(keywords_text)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"WordCloud of Extracted Keywords from Relevant Papers\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "keyword_counts = Counter(keywords_flat)\n",
        "keywords_df = pd.DataFrame(keyword_counts.most_common(30), columns=['keyword', 'frequency'])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='frequency', y='keyword', data=keywords_df)\n",
        "plt.title(\"Top 30 Keyword Frequencies in Relevant Papers\")\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Keyword\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMTAcd6kBd8j"
      },
      "outputs": [],
      "source": [
        "cord19_df['keywords'] = cord19_df.index.map(lambda idx: list(doc_keywords.get(idx, [])))\n",
        "\n",
        "def is_relevant(text):\n",
        "    text = str(text).lower()\n",
        "    return any(k in text for k in ALL_KEYWORDS)\n",
        "\n",
        "cord19_df['is_relevant'] = cord19_df['abstract'].astype(str).apply(is_relevant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwrDDa8tE27L"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load tokenizer + embedding model (use same model for consistency)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFmEzgBZumua"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_tokens=512, overlap=50):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(tokens):\n",
        "        end = min(start + max_tokens, len(tokens))\n",
        "        chunk_tokens = tokens[start:end]\n",
        "        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
        "        chunks.append(chunk_text.strip())\n",
        "        start += max_tokens - overlap  # move forward with overlap\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0kJCz1t3_JQ"
      },
      "outputs": [],
      "source": [
        "source_df = cord19_df[cord19_df['is_relevant']].copy()\n",
        "\n",
        "chunked_docs, doc_ids = [], []\n",
        "\n",
        "for idx, row in tqdm(source_df.iterrows(), total=len(source_df)):\n",
        "    abstract = row.get(\"abstract\", \"\")\n",
        "    chunks = chunk_text(abstract)\n",
        "    chunked_docs.extend(chunks)\n",
        "    doc_ids.extend([idx] * len(chunks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzXp2XHfE-Z_"
      },
      "outputs": [],
      "source": [
        "abstract_embeddings = model.encode(\n",
        "    chunked_docs,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_tensor=True,\n",
        "    truncate=True  # ✅ This prevents index overflow errors\n",
        ")\n",
        "print(\"Embedding shape:\", abstract_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aDpM6m2FAF5"
      },
      "outputs": [],
      "source": [
        "print(\"Example original abstract:\")\n",
        "print(source_df.loc[doc_ids[0], \"abstract\"][:500])\n",
        "\n",
        "print(\"\\nExample chunked version:\")\n",
        "print(chunked_docs[0])\n",
        "\n",
        "print(\"\\nEmbedding shape:\", abstract_embeddings.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV_Rxa4nGZZF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save to disk (Google Drive)\n",
        "with open(os.path.join(PROJECT_DIR, \"chunked_docs.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(chunked_docs, f)\n",
        "\n",
        "with open(os.path.join(PROJECT_DIR, \"doc_ids.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(doc_ids, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fx328loGbKB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Save tensor as binary file\n",
        "torch.save(abstract_embeddings, os.path.join(PROJECT_DIR, \"abstract_embeddings.pt\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suq849nTOKUv"
      },
      "outputs": [],
      "source": [
        "\n",
        "chunked_docs_path = os.path.join(PROJECT_DIR, \"chunked_docs.pkl\")\n",
        "doc_ids_path = os.path.join(PROJECT_DIR, \"doc_ids.pkl\")\n",
        "embedding_path = os.path.join(PROJECT_DIR, \"abstract_embeddings.pt\")\n",
        "source_df_path = os.path.join(PROJECT_DIR, \"source_df_for_chunks.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryf24l-DOAqG"
      },
      "outputs": [],
      "source": [
        "if all(os.path.exists(p) for p in [chunked_docs_path, doc_ids_path, embedding_path, source_df_path]):\n",
        "    print(\"✅ Loaded chunked data from cache.\")\n",
        "\n",
        "    with open(chunked_docs_path, \"rb\") as f:\n",
        "        chunked_docs = pickle.load(f)\n",
        "\n",
        "    with open(doc_ids_path, \"rb\") as f:\n",
        "        doc_ids = pickle.load(f)\n",
        "\n",
        "    abstract_embeddings = torch.load(embedding_path)\n",
        "    source_df = pd.read_csv(source_df_path)\n",
        "\n",
        "else:\n",
        "    print(\"🚀 Starting chunking + embedding...\")\n",
        "\n",
        "    source_df = cord19_df[cord19_df[\"is_relevant\"] & cord19_df[\"abstract\"].notna()].copy()\n",
        "    source_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    source_df.to_csv(source_df_path, index=False)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    def chunk_text(text, max_tokens=512, overlap=50):\n",
        "        tokens = tokenizer.tokenize(str(text))\n",
        "        chunks, start = [], 0\n",
        "        while start < len(tokens):\n",
        "            end = min(start + max_tokens, len(tokens))\n",
        "            chunk = tokenizer.convert_tokens_to_string(tokens[start:end]).strip()\n",
        "            chunks.append(chunk)\n",
        "            start += max_tokens - overlap\n",
        "        return chunks\n",
        "\n",
        "    chunked_docs, doc_ids = [], []\n",
        "\n",
        "    for idx, row in tqdm(source_df.iterrows(), total=len(source_df)):\n",
        "        chunks = chunk_text(row[\"abstract\"])\n",
        "        chunked_docs.extend(chunks)\n",
        "        doc_ids.extend([idx] * len(chunks))\n",
        "\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    abstract_embeddings = model.encode(\n",
        "        chunked_docs,\n",
        "        batch_size=64,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_tensor=True,\n",
        "        truncate=True\n",
        "    )\n",
        "\n",
        "    with open(chunked_docs_path, \"wb\") as f:\n",
        "        pickle.dump(chunked_docs, f)\n",
        "\n",
        "    with open(doc_ids_path, \"wb\") as f:\n",
        "        pickle.dump(doc_ids, f)\n",
        "\n",
        "    torch.save(abstract_embeddings, embedding_path)\n",
        "\n",
        "    print(\"✅ Saved all embeddings and chunked data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfBXy-cdxI95"
      },
      "source": [
        "# Analyze external dataset mentions among relevant keyword-filtered papers\n",
        "\n",
        "Understand how many keyword-relevant papers (pre-topic modeling) are referencing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk01dEiy5F8Y"
      },
      "outputs": [],
      "source": [
        "# ✅ Use the correct column name from current pipeline\n",
        "relevant_papers = cord19_df[cord19_df['is_relevant']]\n",
        "\n",
        "# ✅ Match against Kaggle dataset-linked papers\n",
        "linked = df_meta_cord19['cord_uid'].isin(relevant_papers['cord_uid'])\n",
        "linked_count = linked.sum()\n",
        "\n",
        "print(f\"🔍 {linked_count} out of {len(relevant_papers)} relevant papers reference external datasets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsxAzOU1vbJG"
      },
      "source": [
        "#**Embedding + UMAP**\n",
        "\n",
        "To visualize how documents differ between filtered and removed abstracts using dimensionality reduction (UMAP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJUQ2IIMvoYG"
      },
      "source": [
        "#**BERTopic Topic Modeling**\n",
        "\n",
        "This is for semantic structuring and analysis of the filtered corpus. It helps group related documents by themes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ChdIuT-QxR"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "filtered_df = cord19_df[cord19_df['abstract'].notna()].copy()\n",
        "subset_df = filtered_df.sample(n=7000, random_state=42)\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "bertopic_model = BERTopic(language=\"english\", verbose=True, embedding_model=embedding_model)\n",
        "\n",
        "topics, _ = bertopic_model.fit_transform(subset_df['abstract'].astype(str).tolist())\n",
        "\n",
        "filtered_df[\"topic\"] = -1\n",
        "filtered_df.loc[subset_df.index, \"topic\"] = topics\n",
        "\n",
        "# Topic sizes\n",
        "topic_sizes = filtered_df[\"topic\"].value_counts()\n",
        "print(\"✅ Topic distribution:\")\n",
        "print(topic_sizes.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEs-iXWwwFGP"
      },
      "source": [
        "# Post-topic modeling: Analyze external dataset mentions per topic\n",
        "\n",
        "Understand which topics are associated with dataset-linked papers, and how strong the signal is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb9bLk0iwM4s"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5SxmRNQVAm"
      },
      "outputs": [],
      "source": [
        "# ✅ Already applied above:\n",
        "# filtered_df[\"topic\"] = -1\n",
        "# filtered_df.loc[subset_df.index, \"topic\"] = topics\n",
        "\n",
        "# ✅ Create set of known dataset-linked cord_uids\n",
        "referenced_uids = set(df_meta_cord19[\"cord_uid\"])\n",
        "\n",
        "# ✅ Mark which papers reference datasets\n",
        "filtered_df[\"has_dataset_reference\"] = filtered_df[\"cord_uid\"].isin(referenced_uids)\n",
        "\n",
        "# ✅ Group by topic\n",
        "topic_to_corduids = defaultdict(list)\n",
        "for index, row in filtered_df.iterrows():\n",
        "    topic = row['topic']\n",
        "    if topic != -1:\n",
        "        topic_to_corduids[topic].append(row['cord_uid'])\n",
        "\n",
        "# ✅ Count dataset links per topic\n",
        "external_ref_counts = {\n",
        "    topic: df_meta_cord19['cord_uid'].isin(uids).sum()\n",
        "    for topic, uids in topic_to_corduids.items()\n",
        "}\n",
        "\n",
        "# ✅ Count documents per topic\n",
        "topic_sizes = filtered_df['topic'].value_counts().to_dict()\n",
        "topic_sizes.pop(-1, None)  # remove unassigned\n",
        "\n",
        "# ✅ Combine size + dataset linkage summary\n",
        "summary = []\n",
        "for topic in sorted(topic_to_corduids.keys()):\n",
        "    size = topic_sizes.get(topic, 0)\n",
        "    dataset_refs = external_ref_counts.get(topic, 0)\n",
        "    summary.append((topic, size, dataset_refs))\n",
        "\n",
        "# ✅ Report: Only topics with 10+ papers\n",
        "MIN_TOPIC_SIZE = 10\n",
        "print(\"📊 Topics with dataset-linked paper counts:\\n\")\n",
        "for topic, size, refs in summary:\n",
        "    if size >= MIN_TOPIC_SIZE:\n",
        "        print(f\"Topic {topic:4d} | Size: {size:4d} | Dataset-linked papers: {refs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp6VMdLyP6xB"
      },
      "source": [
        "#Vector DB with LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paNQ7mnwsvtY"
      },
      "outputs": [],
      "source": [
        "# core LlamaIndex\n",
        "!pip install llama-index\n",
        "\n",
        "# the HuggingFace embeddings integration\n",
        "!pip install llama-index-embeddings-huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Zr-lEhXNY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader, ServiceContext, Document\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0BaFpJBKaHd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    row = source_df.iloc[doc_ids[501689]]\n",
        "    print(\"✅ Aligned.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Misaligned:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPMLt4P9Z9Bc"
      },
      "outputs": [],
      "source": [
        "!pip install -q joblib\n",
        "!pip install -q tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXjMqQ1DhsuS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.settings import Settings\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "# Paths\n",
        "vector_index_path = os.path.join(PROJECT_DIR, \"vector_index_sample_5000new\")\n",
        "\n",
        "# Load chunked docs and metadata\n",
        "with open(os.path.join(PROJECT_DIR, \"chunked_docs.pkl\"), \"rb\") as f:\n",
        "    chunked_docs = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(PROJECT_DIR, \"doc_ids.pkl\"), \"rb\") as f:\n",
        "    doc_ids = pickle.load(f)\n",
        "\n",
        "source_df = pd.read_csv(os.path.join(PROJECT_DIR, \"source_df_for_chunks.csv\"))\n",
        "\n",
        "# Truncate to 5,000 sample\n",
        "chunked_docs = chunked_docs[:5000]\n",
        "doc_ids = doc_ids[:5000]\n",
        "source_rows = source_df.to_dict(\"records\")\n",
        "\n",
        "# ✅ Set embed model BEFORE index creation\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\", device=\"cuda\", max_length=512, show_progress_bar=True)\n",
        "Settings.embed_model = embed_model\n",
        "Settings.node_parser = SimpleNodeParser.from_defaults()\n",
        "# Optional flags\n",
        "dataset_linked_uids = set()\n",
        "source_df[\"is_dataset_linked\"] = source_df[\"cord_uid\"].isin(dataset_linked_uids)\n",
        "source_df[\"is_smoking_keyword\"] = source_df[\"abstract\"].apply(\n",
        "    lambda x: any(kw.lower() in str(x).lower() for kw in SMOKING_KEYWORDS)\n",
        ")\n",
        "\n",
        "def build_document(chunk, doc_id):\n",
        "    row = source_rows[doc_id]\n",
        "    metadata = {\n",
        "        \"cord_uid\": str(row.get(\"cord_uid\")),\n",
        "        \"title\": str(row.get(\"title\", \"\"))[:200],\n",
        "        \"keywords\": list(row.get(\"keywords\", []))[:5],\n",
        "        \"is_relevant\": bool(row.get(\"is_relevant\", False)),\n",
        "        \"is_smoking_keyword\": bool(row.get(\"is_smoking_keyword\", False)),\n",
        "        \"is_dataset_linked\": bool(row.get(\"is_dataset_linked\", False)),\n",
        "        \"topic\": int(row.get(\"topic\", -1)) if \"topic\" in row else -1\n",
        "    }\n",
        "    return Document(text=chunk, metadata=metadata)  # ✅ Allow LlamaIndex to embed\n",
        "\n",
        "# Build docs in parallel\n",
        "documents = Parallel(n_jobs=-1, backend=\"threading\")(\n",
        "    delayed(build_document)(chunk, doc_id)\n",
        "    for chunk, doc_id in tqdm(zip(chunked_docs, doc_ids), total=len(chunked_docs), desc=\"📄 Creating Documents\")\n",
        ")\n",
        "\n",
        "# ⚠️ Remove old index if it exists\n",
        "if os.path.exists(vector_index_path):\n",
        "    import shutil\n",
        "    shutil.rmtree(vector_index_path)\n",
        "\n",
        "# ✅ Build new index with embedded docs\n",
        "#service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
        "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, show_progress=True)\n",
        "index.storage_context.persist(persist_dir=vector_index_path)\n",
        "print(\"✅ Sample index rebuilt with embedded documents.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VinRS4MmCPnS"
      },
      "outputs": [],
      "source": [
        "print(documents[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktEKGR_vCT5I"
      },
      "outputs": [],
      "source": [
        "print(Settings.embed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNDxCpT802cS"
      },
      "source": [
        "#QA-Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-akBgLnWdN5"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-embeddings-huggingface llama-index-llms-huggingface bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnoxGK7GxJDu"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade \"llama-index>=0.6.10\" llama-index-embeddings-huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN5Ti-LNiEvS"
      },
      "outputs": [],
      "source": [
        "# prompt: install dependency for llama_index.retrievers\n",
        "\n",
        "!pip install llama-index-retrievers-bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t4yLN2ZSkxG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")  #  actual token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1KTY-ElsWe"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2JMe1jBTDqb"
      },
      "outputs": [],
      "source": [
        "# === Load the Meta LLM via HuggingFace ===\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "   model_name=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
        "    tokenizer=tokenizer,\n",
        "    context_window=4096,\n",
        "    max_new_tokens=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRANShZA0vN4"
      },
      "outputs": [],
      "source": [
        "# === Import Required Modules ===\n",
        "from llama_index.core import Settings, Document, StorageContext, VectorStoreIndex, ServiceContext, load_index_from_storage\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUUZ5v6c9mHP"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from sentence_transformers import util\n",
        "import torch\n",
        "\n",
        "class SemanticBoostRetriever(BaseRetriever):\n",
        "    \"\"\"\n",
        "    A retriever that:\n",
        "      1. Retrieves candidates from base retriever.\n",
        "      2. Embeds the query via embed_model.get_query_embedding(...)\n",
        "      3. Computes cosine similarity with each node.\n",
        "      4. If node.embedding is missing, computes it on the fly.\n",
        "      5. Boosts dataset-linked documents.\n",
        "      6. Optionally filters to smoking or topic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_retriever: BaseRetriever,\n",
        "        embed_model,\n",
        "        similarity_threshold: float = 0.3,\n",
        "        boost_factor: float = 2.0,\n",
        "        filter_smoking: bool = False,\n",
        "        topic_filter: int = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.retriever = base_retriever\n",
        "        self.embed_model = embed_model\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "        self.boost_factor = boost_factor\n",
        "        self.filter_smoking = filter_smoking\n",
        "        self.topic_filter = topic_filter\n",
        "\n",
        "        # Safety checks\n",
        "        if isinstance(embed_model, list):\n",
        "            raise ValueError(\"Expected a single embed_model, but got a list.\")\n",
        "\n",
        "        if not hasattr(embed_model, \"get_query_embedding\"):\n",
        "            raise ValueError(\"Embed model must support .get_query_embedding(...)\")\n",
        "\n",
        "    def _retrieve(self, query_bundle):\n",
        "        query_str = query_bundle.query_str\n",
        "\n",
        "        # Step 1: Get candidates from base retriever\n",
        "        candidate_nodes = self.retriever.retrieve(query_bundle) or []\n",
        "\n",
        "        # Step 2: Embed the query\n",
        "        query_vector = self.embed_model.get_query_embedding(query_str)\n",
        "        query_tensor = torch.tensor(query_vector).unsqueeze(0)  # (1, D)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for node in candidate_nodes:\n",
        "            # Step 3: Fallback embedding if not already embedded\n",
        "            if node.embedding is None:\n",
        "                try:\n",
        "                    node.embedding = self.embed_model.get_text_embedding(node.text)\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Failed to embed node {node.node_id}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            node_tensor = torch.tensor(node.embedding).unsqueeze(0)  # (1, D)\n",
        "            sim_score = util.cos_sim(query_tensor, node_tensor).item()\n",
        "\n",
        "            # Step 4: Filter by similarity threshold\n",
        "            if sim_score < self.similarity_threshold:\n",
        "                continue\n",
        "\n",
        "            # Step 5: Optional filter for smoking-related\n",
        "            if self.filter_smoking and not node.metadata.get(\"is_smoking_keyword\", False):\n",
        "                continue\n",
        "\n",
        "            # Step 6: Optional topic filter\n",
        "            if self.topic_filter is not None:\n",
        "                if node.metadata.get(\"topic\") != self.topic_filter:\n",
        "                    continue\n",
        "\n",
        "            # Step 7: Boost score if linked to dataset\n",
        "            if node.metadata.get(\"is_dataset_linked\", False):\n",
        "                node.score *= self.boost_factor\n",
        "\n",
        "            results.append(node)\n",
        "\n",
        "        if not results:\n",
        "            return candidate_nodes[:10]  # fallback\n",
        "\n",
        "        results.sort(key=lambda n: n.score, reverse=True)\n",
        "        return results[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usHZWn_Q6NKf"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.prompt_helper import PromptHelper\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "# Add PromptHelper to safely manage prompt sizes\n",
        "# Reason: Prevent context overflow errors by automatically adjusting the size of prompts and chunks.\n",
        "# It ensures that:\n",
        "#   - Total tokens (input + output) stay within model limits (e.g. 4096)\n",
        "#   - Long documents are chunked efficiently (e.g. overlapping content preserved)\n",
        "#   - Helps maintain performance and avoids runtime crashes\n",
        "Settings.prompt_helper = PromptHelper(\n",
        "    context_window=4096,     # Max context tokens LLM supports\n",
        "             # Expected max response size from the LLM\n",
        "    #chunk_overlap_ratio=0.1, # Overlap between chunks to retain context across boundaries\n",
        "    tokenizer=tokenizer  # Use tokenizer of the loaded LLM\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0YDVe1rvjU-"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = \"/content/drive/MyDrive/Colab Notebooks/ANLP_Project\"\n",
        "index_path = os.path.join(PROJECT_DIR, \"vector_index_sample_5000new\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRYkN9Lr6YFo"
      },
      "outputs": [],
      "source": [
        "# 2. Load vector index and apply custom retriever\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
        "\n",
        "index = load_index_from_storage(storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7h6nM3vN3Bx"
      },
      "outputs": [],
      "source": [
        "print(index.docstore.docs.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQQD5YtLlWPF"
      },
      "outputs": [],
      "source": [
        "# Get the base retriever\n",
        "base_retriever = index.as_retriever(retriever_mode=\"embedding\", similarity_top_k=50)\n",
        "\n",
        "retriever = SemanticBoostRetriever(\n",
        "    base_retriever=base_retriever,\n",
        "    embed_model=embed_model,\n",
        "    similarity_threshold=0.6,      # 🔧 Tune based on quality\n",
        "    boost_factor=2.0,              # 🚀 Boost dataset-linked docs\n",
        "    filter_smoking=False,          # 🔥 Optional: focus on smoking topics\n",
        "    topic_filter= None              # 🎯 Optional: filter to a specific topic ID\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzsz5DG5KK7Q"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from llama_index.core.chat_engine import ContextChatEngine\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_wRBMuu6O3v"
      },
      "outputs": [],
      "source": [
        "# 4. Build chat engine with system prompt + memory + boosted retriever\n",
        "system_prompt = (\n",
        "    \"You are a biomedical assistant trained to answer questions about COVID-19, smoking, \"\n",
        "    \"and the correlation between the two. Your answers are based strictly on scientific abstracts. \"\n",
        "    \"Do not give general health advice. Only respond using information retrieved from research data.\"\n",
        ")\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(retriever=retriever, llm=llm)\n",
        "chat_engine = ContextChatEngine.from_defaults(\n",
        "    retriever=retriever,\n",
        "    llm=llm,\n",
        "    memory=ChatMemoryBuffer.from_defaults(token_limit=32000),\n",
        "    system_prompt=system_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Keine GPU\"\n",
        "total_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3) if torch.cuda.is_available() else 0\n",
        "print(f\"GPU: {gpu_name} mit insgesamt {total_mem:.1f} GiB VRAM\")\n"
      ],
      "metadata": {
        "id": "BHrkGPb8TL3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Irgendwo vor der Textgenerierung\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "fK8eehVXT3qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PBOB3aIIQCt"
      },
      "outputs": [],
      "source": [
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# 1) Two‐Stage Reranker + Reader Helper (in‐notebook)\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from llama_index.core import QueryBundle\n",
        "\n",
        "# Load a pretrained bi‐encoder (only once)\n",
        "reranker = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def two_stage_answer(query: str, top_k_retrieve: int = 50, top_k_rerank: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Stage 1: retriever.retrieve(...) → top_k_retrieve candidates\n",
        "    Stage 2: rerank those candidates with Sentence‐Transformer; keep top_k_rerank\n",
        "    Stage 3: feed top passages into chat_engine.stream_chat(...) and return final answer\n",
        "    \"\"\"\n",
        "    # ── Stage 1: Semantic‐boost retrieval\n",
        "    qb = QueryBundle(query_str=query)\n",
        "    candidates = retriever.retrieve(qb) or []\n",
        "    candidates = candidates[:top_k_retrieve]\n",
        "    if not candidates:\n",
        "        return \"No passages retrieved.\"\n",
        "\n",
        "    # Extract raw texts\n",
        "    docs = [node.node.get_text() for node in candidates]\n",
        "\n",
        "    # ── Stage 2: embed query + docs, compute cosine scores\n",
        "    query_emb = reranker.encode(query, convert_to_tensor=True)\n",
        "    docs_emb  = reranker.encode(docs,  convert_to_tensor=True)\n",
        "    cosine_scores = util.cos_sim(query_emb, docs_emb)[0]  # shape: (top_k_retrieve,)\n",
        "\n",
        "    # Pick the indices of the top_k_rerank documents\n",
        "    topk_idxs = torch.topk(\n",
        "        cosine_scores,\n",
        "        k=min(top_k_rerank, len(docs)),\n",
        "        largest=True\n",
        "    ).indices.tolist()\n",
        "\n",
        "    # Build the reranked context\n",
        "    reranked_passages = [docs[i] for i in topk_idxs]\n",
        "    context_text = \"\\n\\n\".join(reranked_passages)\n",
        "\n",
        "    # ── Stage 3: Ask the LLM with an extractive prompt\n",
        "    prompt = (\n",
        "        \"You are a biomedical QA assistant. Find the single sentence that answers the question \"\n",
        "        \"and output that sentence verbatim. If no answer is present, say \\\"No answer in retrieved passages.\\\".\\n\\n\"\n",
        "        f\"Passages:\\n{context_text}\\n\\n\"\n",
        "        f\"Question: {query}\\n\"\n",
        "        \"Exact sentence (copy verbatim):\"\n",
        "    )\n",
        "\n",
        "    response = chat_engine.stream_chat(prompt)\n",
        "    answer = \"\".join([tok for tok in response.response_gen]).strip()\n",
        "    return answer\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# 2) Test it right here in the notebook\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "test_q = \"How does nicotine affect ACE2 expression in lung tissue?\"\n",
        "print(\"Two‐Stage Answer:\", two_stage_answer(test_q, top_k_retrieve=50, top_k_rerank=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input(\">>> \")\n",
        "    if query.lower().strip() == \"quit\":\n",
        "        break\n",
        "\n",
        "    print(\"Agent: \", end=\"\", flush=True)\n",
        "    # call our two‐stage pipeline instead of direct stream_chat\n",
        "    answer = two_stage_answer(query, top_k_retrieve=50, top_k_rerank=5)\n",
        "    print(answer)\n",
        "    chat_engine.reset()\n"
      ],
      "metadata": {
        "id": "l6Ffp7_VWdzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W71wSFFB4bjw"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    query = input(\"> \")\n",
        "    if query.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    # Streamelt válasz\n",
        "    print(\"Agent: \", end=\"\", flush=True)\n",
        "    response = chat_engine.stream_chat(query)\n",
        "    for token in response.response_gen:\n",
        "        print(token, end=\"\", flush=True)\n",
        "    print()\n",
        "\n",
        "\n",
        "chat_engine.reset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyeIM0sQ4jyF"
      },
      "outputs": [],
      "source": [
        "# prompt: implement validation methods to test the agent model performance\n",
        "\n",
        "import pandas as pd\n",
        "# Define validation methods\n",
        "def evaluate_response(query: str, expected_answer: str, agent_response: str) -> dict:\n",
        "    \"\"\"Evaluates a single response based on expected answer and keywords.\"\"\"\n",
        "    evaluation = {\n",
        "        \"query\": query,\n",
        "        \"expected_answer\": expected_answer,\n",
        "        \"agent_response\": agent_response,\n",
        "        \"contains_expected_keywords\": False,\n",
        "        \"is_relevant_to_query\": False, # Requires manual review or more sophisticated NLP\n",
        "        \"uses_retrieved_context\": False # Requires analyzing source nodes\n",
        "    }\n",
        "\n",
        "    # Simple keyword check for relevance\n",
        "    expected_keywords = set(expected_answer.lower().split())\n",
        "    response_words = set(agent_response.lower().split())\n",
        "    common_keywords = expected_keywords.intersection(response_words)\n",
        "\n",
        "    if len(common_keywords) > 0:\n",
        "        evaluation[\"contains_expected_keywords\"] = True\n",
        "\n",
        "    # Placeholder for more advanced checks\n",
        "    # For 'is_relevant_to_query' and 'uses_retrieved_context', you'd need more complex NLP\n",
        "    # or access to the source nodes the agent used.\n",
        "\n",
        "    return evaluation\n",
        "\n",
        "def run_evaluation_suite(queries_and_answers: list):\n",
        "    \"\"\"Runs a suite of queries through the agent and evaluates responses.\"\"\"\n",
        "    results = []\n",
        "    print(\"\\n--- Running Agent Evaluation Suite ---\")\n",
        "    for query, expected_answer in tqdm(queries_and_answers, desc=\"Evaluating Agent\"):\n",
        "        try:\n",
        "            # Get response from the agent\n",
        "            # Assuming chat_engine is accessible from the previous code\n",
        "            response_stream = chat_engine.stream_chat(query)\n",
        "            agent_response_tokens = [token for token in response_stream.response_gen]\n",
        "            agent_response = \"\".join(agent_response_tokens).strip()\n",
        "\n",
        "            # Evaluate the response\n",
        "            evaluation_result = evaluate_response(query, expected_answer, agent_response)\n",
        "            results.append(evaluation_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing query '{query}': {e}\")\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"expected_answer\": expected_answer,\n",
        "                \"agent_response\": f\"ERROR: {e}\",\n",
        "                \"contains_expected_keywords\": False,\n",
        "                \"is_relevant_to_query\": False,\n",
        "                \"uses_retrieved_context\": False\n",
        "            })\n",
        "\n",
        "    print(\"--- Evaluation Complete ---\")\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Define a list of queries and their expected answers for testing\n",
        "# These should ideally be derived from your dataset or knowledge base\n",
        "test_cases = [\n",
        "    (\"What is the link between smoking and COVID-19 severity?\", \"Smoking is associated with increased severity of COVID-19.\"),\n",
        "    (\"Does vaping increase the risk of COVID-19 infection?\", \"Some studies suggest vaping may be a risk factor, but more research is needed.\"),\n",
        "    (\"Are former smokers at higher risk for severe COVID-19?\", \"Former smokers might have residual lung damage affecting COVID-19 outcomes.\"),\n",
        "    (\"Mention a study related to tobacco use and coronavirus.\", \"Look for papers discussing SARS-CoV-2 and smoking habits.\"),\n",
        "    (\"What datasets are linked to papers on COVID-19 and smoking?\", \"Find papers in the dataset-linked category that also mention smoking keywords.\")\n",
        "]\n",
        "\n",
        "# Run the evaluation suite\n",
        "evaluation_df = run_evaluation_suite(test_cases)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nEvaluation Results:\")\n",
        "display(evaluation_df)\n",
        "\n",
        "# Analyze results\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(evaluation_df[\"contains_expected_keywords\"].value_counts(normalize=True))\n",
        "\n",
        "# You would typically add more sophisticated metrics:\n",
        "# - ROUGE scores (for recall/precision of n-grams compared to expected answer)\n",
        "# - Semantic similarity between agent response and expected answer (e.g., using another embedding model)\n",
        "# - Manual review for relevance and factual correctness\n",
        "# - Checks if the response cites or is based on the retrieved nodes (requires modifying the agent or analyzing its output structure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-bbtC4-3_Ej"
      },
      "outputs": [],
      "source": [
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# Two‐Stage Reranking + Reader Example\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from llama_index.core import QueryBundle\n",
        "\n",
        "# 1) Load a pretrained bi‐encoder as reranker\n",
        "#    You can swap in any Sentence‐Transformer model (e.g. \"all-mpnet-base-v2\").\n",
        "reranker = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 2) A helper function to do reranking on top_K candidates\n",
        "def rerank_and_read(query: str, top_k_retrieve: int = 10, top_k_rerank: int = 3):\n",
        "    \"\"\"\n",
        "    1) Retrieve top_k_retrieve passages via retriever.\n",
        "    2) Embed query + passages with `reranker`, compute cosine scores.\n",
        "    3) Take top top_k_rerank passages, join them into a single context.\n",
        "    4) Call chat_engine.predict(...) on that concatenated context+query.\n",
        "    \"\"\"\n",
        "\n",
        "    # ── Stage 1: retrieve top_k_retrieve candidates ─────────────────────────────\n",
        "    qb = QueryBundle(query_str=query)\n",
        "    candidates = retriever.retrieve(qb) or []\n",
        "    candidates = candidates[:top_k_retrieve]\n",
        "\n",
        "    if len(candidates) == 0:\n",
        "        return \"No passages retrieved.\"\n",
        "\n",
        "    # Extract their texts\n",
        "    docs = [node.node.get_text() for node in candidates]\n",
        "\n",
        "    # ── Stage 2: rerank those K by cosine similarity ────────────────────────────\n",
        "    #    Embed the query once, embed all K document texts, compute sim scores in batch.\n",
        "    query_emb = reranker.encode(query, convert_to_tensor=True)\n",
        "    docs_emb  = reranker.encode(docs,  convert_to_tensor=True)\n",
        "    # cosine_sim is a 1×K tensor\n",
        "    cosine_scores = util.cos_sim(query_emb, docs_emb)[0]  # shape: (K,)\n",
        "\n",
        "    # Sort indices by descending score, pick top_k_rerank\n",
        "    topk_idxs = torch.topk(cosine_scores, k=min(top_k_rerank, len(docs)), largest=True).indices\n",
        "    topk_idxs = topk_idxs.tolist()\n",
        "\n",
        "    # Build the reranked context_text by concatenating the chosen passages\n",
        "    reranked_passages = [docs[i] for i in topk_idxs]\n",
        "    context_text = \"\\n\\n\".join(reranked_passages)\n",
        "\n",
        "    # ── Stage 3: feed reranked context into your LLM reader ────────────────────\n",
        "    prompt = (\n",
        "        \"You are a biomedical QA assistant. Use ONLY the passages below to answer EXACTLY. \"\n",
        "        \"If no answer is present, say \\\"No answer in retrieved passages.\\\".\\n\\n\"\n",
        "        f\"Passages:\\n{context_text}\\n\\n\"\n",
        "        f\"Question: {query}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    # Use chat_engine.predict(...) so you get the full string\n",
        "        # Use stream_chat instead of predict()\n",
        "    response = chat_engine.stream_chat(prompt)\n",
        "    answer = \"\".join([token for token in response.response_gen]).strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "# 3) Example usage: Evaluate a single question\n",
        "q = \"How does nicotine affect ACE2 expression in lung tissue?\"\n",
        "print(\"Agent’s answer:\", rerank_and_read(q, top_k_retrieve=10, top_k_rerank=3))\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# (Optional) Batch‐evaluate on test_set (token‐F1 or human grade)\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "import json, re\n",
        "from collections import Counter\n",
        "\n",
        "# Load a small test list of {question, reference} for fuzzy‐match evaluation.\n",
        "eval_questions = [\n",
        "    {\"question\": \"Which receptor does SARS-CoV-2 use to enter lung cells?\",\n",
        "     \"reference\": \"ACE2 receptor\"},\n",
        "    {\"question\": \"What is the primary carcinogen in cigarette smoke?\",\n",
        "     \"reference\": \"Benzopyrene\"},\n",
        "    # … add 20–30 more …\n",
        "]\n",
        "\n",
        "def normalize(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "def token_f1(pred: str, ref: str) -> float:\n",
        "    ptoks = normalize(pred).split()\n",
        "    rtoks = normalize(ref).split()\n",
        "    common = Counter(ptoks) & Counter(rtoks)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0.0\n",
        "    p = num_same / len(ptoks)\n",
        "    r = num_same / len(rtoks)\n",
        "    return 2 * (p*r) / (p + r)\n",
        "\n",
        "scores = []\n",
        "for entry in eval_questions:\n",
        "    q_text = entry[\"question\"]\n",
        "    ref    = entry[\"reference\"]\n",
        "    pred   = rerank_and_read(q_text, top_k_retrieve=10, top_k_rerank=3)\n",
        "    scores.append(token_f1(pred, ref))\n",
        "\n",
        "print(\"Avg token‐F1 on eval set:\", sum(scores) / len(scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_djJJjn9Dlq"
      },
      "outputs": [],
      "source": [
        "# prompt: install rouge\n",
        "\n",
        "!pip install rouge --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ7cyd5Tusn7"
      },
      "outputs": [],
      "source": [
        "# prompt: Use Python in Colab to evaluate the performance of a question-answering agent. Visualize the following metrics over a test set of question-answer pairs\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from rouge import Rouge\n",
        "\n",
        "# --- Evaluation ---\n",
        "# Create a test set of question-answer pairs (manual creation or from a benchmark)\n",
        "test_set = [\n",
        "    (\"What is the relationship between smoking and severe COVID-19 outcomes?\", \"Smoking is associated with increased severity and mortality in COVID-19 patients.\"),\n",
        "    (\"Does smoking increase the risk of contracting COVID-19?\", \"Current evidence suggests smoking may increase susceptibility to SARS-CoV-2 infection.\"),\n",
        "    (\"How does nicotine affect the ACE2 receptor?\", \"Research suggests nicotine may upregulate ACE2 receptor expression, which could potentially increase SARS-CoV-2 entry.\"),\n",
        "    (\"Are e-cigarettes linked to severe COVID-19?\", \"Studies indicate that e-cigarette use may also be associated with increased risk of severe COVID-19.\"),\n",
        "    (\"What are the long-term respiratory effects of smoking after COVID-19?\", \"Smoking may exacerbate long-term respiratory complications following COVID-19.\")\n",
        "]\n",
        "\n",
        "# Store agent responses\n",
        "agent_responses = []\n",
        "for question, _ in test_set:\n",
        "    # Get response from the chat engine\n",
        "    response = chat_engine.chat(question) # Use chat() for non-streaming in eval\n",
        "    agent_responses.append(str(response))\n",
        "\n",
        "# Prepare for evaluation\n",
        "true_answers = [ans for _, ans in test_set]\n",
        "\n",
        "# 1. ROUGE Score (measures overlap between agent and true answers)\n",
        "rouge = Rouge()\n",
        "rouge_scores = rouge.get_scores(agent_responses, true_answers, avg=True)\n",
        "print(\"\\nROUGE Scores:\")\n",
        "print(rouge_scores)\n",
        "\n",
        "# Note: For a true QA evaluation, you would need a way to score answers as correct/incorrect,\n",
        "# which usually requires human annotation or a carefully designed scoring system.\n",
        "# The metrics below are illustrative and would require binary labels (e.g., is the answer correct?).\n",
        "# Since we don't have binary labels for this task, we'll skip accuracy, precision, recall, F1.\n",
        "\n",
        "# --- Visualization ---\n",
        "\n",
        "# Function to visualize ROUGE scores\n",
        "def plot_rouge_scores(rouge_scores):\n",
        "    rouge_types = list(rouge_scores.keys())\n",
        "    metrics = ['r', 'p', 'f'] # recall, precision, f-score\n",
        "    metric_labels = {'r': 'Recall', 'p': 'Precision', 'f': 'F1-Score'}\n",
        "\n",
        "    data = []\n",
        "    for rt in rouge_types:\n",
        "        for met in metrics:\n",
        "            data.append({'ROUGE Type': rt.upper(), 'Metric': metric_labels[met], 'Score': rouge_scores[rt][met]})\n",
        "\n",
        "    df_rouge = pd.DataFrame(data)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=df_rouge, x='Metric', y='Score', hue='ROUGE Type')\n",
        "    plt.title('ROUGE Scores for QA Agent')\n",
        "    plt.ylabel('Score')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_rouge_scores(rouge_scores)\n",
        "\n",
        "# Note: More comprehensive QA evaluation often involves metrics like F1 score on extracted answers (like in SQuAD)\n",
        "# or using an independent QA model to score the generated answers against references.\n",
        "# This ROUGE-based approach gives a measure of semantic overlap, which is a good start.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5puWqjA-_h2"
      },
      "outputs": [],
      "source": [
        "!pip install bert_score  --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-fAL-l-BxlZ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Hugging Face evaluation package\n",
        "pip install git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVjdqJBu-q0y"
      },
      "outputs": [],
      "source": [
        "# prompt: Evaluate With Semantic Similarity\n",
        "#     compute  BERTScore or BLEURT to capture semantic match.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "# 2. BERTScore\n",
        "# Load the BERTScore metric\n",
        "bertscore = load_metric(\"bertscore\")\n",
        "\n",
        "# Compute BERTScore\n",
        "bertscore_results = bertscore.compute(\n",
        "    predictions=agent_responses,\n",
        "    references=true_answers,\n",
        "    lang=\"en\",\n",
        "    model_type=\"bert-base-uncased\" # Can try other models like 'roberta-base'\n",
        ")\n",
        "\n",
        "print(\"\\nBERTScore Results:\")\n",
        "# BERTScore provides precision, recall, and F1 for each prediction-reference pair.\n",
        "# Let's print the average F1 score as a single metric.\n",
        "print(f\"Average BERTScore F1: {sum(bertscore_results['f1']) / len(bertscore_results['f1'])}\")\n",
        "# You can also inspect individual scores:\n",
        "# print(\"Individual BERTScore F1s:\", bertscore_results['f1'])\n",
        "\n",
        "\n",
        "# 3. BLEURT (Requires checkpoint download, can be slow first time)\n",
        "# BLEURT is typically used for evaluating machine translation, but can also be used for\n",
        "# evaluating text generation where a reference is available.\n",
        "# It requires a pre-trained checkpoint. You can specify one, or it will try to download a default.\n",
        "\n",
        "# try:\n",
        "#     bleurt = load_metric(\"bleurt\", checkpoint=\"bleurt-base-512\")\n",
        "#     bleurt_results = bleurt.compute(predictions=agent_responses, references=true_answers)\n",
        "\n",
        "#     print(\"\\nBLEURT Results:\")\n",
        "#     # BLEURT provides a score for each prediction-reference pair.\n",
        "#     # Let's print the average score.\n",
        "#     print(f\"Average BLEURT Score: {sum(bleurt_results['scores']) / len(bleurt_results['scores'])}\")\n",
        "#     # print(\"Individual BLEURT Scores:\", bleurt_results['scores'])\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(f\"\\nCould not compute BLEURT: {e}\")\n",
        "#     print(\"BLEURT requires downloading a checkpoint which might fail or take time.\")\n",
        "#     print(\"Consider running this part separately or handling potential errors.\")\n",
        "#     print(\"Check BLEURT documentation for available checkpoints and installation steps.\")\n",
        "#     # Example of handling: if checkpoint fails, you might just skip BLEURT or use a local path if pre-downloaded.\n",
        "\n",
        "# --- Visualization for BERTScore F1 ---\n",
        "\n",
        "def plot_bertscore_f1(bertscore_results):\n",
        "    f1_scores = bertscore_results['f1']\n",
        "    questions = [f\"Q{i+1}\" for i in range(len(f1_scores))]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=questions, y=f1_scores)\n",
        "    plt.title('BERTScore F1 for each QA Pair')\n",
        "    plt.ylabel('BERTScore F1')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_bertscore_f1(bertscore_results)\n",
        "\n",
        "\n",
        "# Note: Evaluating LLM responses for factual correctness is complex.\n",
        "# Semantic similarity metrics like BERTScore and BLEURT give a sense of how similar the *meaning*\n",
        "# is between the generated answer and the reference answer, which is better than simple word overlap (like ROUGE)\n",
        "# for capturing paraphrasing or different wording that conveys the same information.\n",
        "# However, they don't guarantee factual accuracy. A high score means the answer is semantically close to the *reference*,\n",
        "# but if the reference is wrong, the score will still be high for a semantically similar wrong answer.\n",
        "# A truly robust evaluation often involves:\n",
        "# 1. Fact-checking the agent's response against the source documents or external knowledge.\n",
        "# 2. Human evaluation for relevance, coherence, completeness, and accuracy.\n",
        "# 3. Using reference answers that are verified to be correct and comprehensive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pJQEpMPruM6"
      },
      "outputs": [],
      "source": [
        "# Create dev_set.json directly\n",
        "import json\n",
        "\n",
        "dev_questions = [\n",
        "    {\n",
        "        \"question\": \"Which receptor does SARS-CoV-2 use to enter lung cells?\",\n",
        "        \"gold_node_ids\": [\"abc156\"],\n",
        "        \"gold_answer\": \"ACE2 receptor\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the primary carcinogen in cigarette smoke?\",\n",
        "        \"gold_node_ids\": [\"acf123\"],\n",
        "        \"gold_answer\": \"Benzopyrene\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Does active smoking increase the risk of severe COVID-19?\",\n",
        "        \"gold_node_ids\": [\"abc123\"],\n",
        "        \"gold_answer\": \"Yes, active smokers have a higher risk of severe COVID-19.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the incubation period of COVID-19?\",\n",
        "        \"gold_node_ids\": [\"def456\"],\n",
        "        \"gold_answer\": \"Approximately 2 to 14 days\"\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(\"dev_set.json\", \"w\") as f:\n",
        "    json.dump(dev_questions, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApaMnUvprvKw"
      },
      "outputs": [],
      "source": [
        "# Create test_set.json directly\n",
        "import json\n",
        "\n",
        "test_questions = [\n",
        "    {\n",
        "        \"question\": \"What are the most common symptoms of COVID-19?\",\n",
        "        \"gold_node_ids\": [\"ghi789\"],\n",
        "        \"gold_answer\": \"Fever, dry cough, and fatigue\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Which lung disease is most strongly linked to chronic smoking?\",\n",
        "        \"gold_node_ids\": [\"jkl012\"],\n",
        "        \"gold_answer\": \"Chronic obstructive pulmonary disease\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does nicotine affect ACE2 expression in lung tissue?\",\n",
        "        \"gold_node_ids\": [\"jkl076\"],\n",
        "        \"gold_answer\": \"Nicotine upregulates ACE2 expression in lung epithelial cells\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Is there a difference in COVID-19 mortality between smokers and non-smokers?\",\n",
        "        \"gold_node_ids\": [\"jdp012\"],\n",
        "        \"gold_answer\": \"Smokers have higher COVID-19 mortality rates than non-smokers\"\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(\"test_set.json\", \"w\") as f:\n",
        "    json.dump(test_questions, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-FX7v8UqAu-"
      },
      "outputs": [],
      "source": [
        "# 1) Overwrite dev_set.json and test_set.json so that each gold_node_ids becomes\n",
        "#    the top‐1 retrieved node_id for that question (for quick alignment).\n",
        "\n",
        "import json\n",
        "from llama_index.core import QueryBundle\n",
        "\n",
        "# Load current question lists\n",
        "with open(\"dev_set.json\",  \"r\") as f:\n",
        "    dev_questions  = json.load(f)\n",
        "with open(\"test_set.json\", \"r\") as f:\n",
        "    test_questions = json.load(f)\n",
        "\n",
        "# For each question, retrieve the top‐1 node and replace gold_node_ids with its node_id\n",
        "def align_gold_ids(retriever, question_list):\n",
        "    for entry in question_list:\n",
        "        q_text = entry[\"question\"]\n",
        "        qb = QueryBundle(query_str=q_text)\n",
        "        candidates = retriever.retrieve(qb) or []\n",
        "        if candidates:\n",
        "            entry[\"gold_node_ids\"] = [candidates[0].node_id]\n",
        "        else:\n",
        "            entry[\"gold_node_ids\"] = []  # no candidate found\n",
        "    return question_list\n",
        "\n",
        "dev_questions  = align_gold_ids(retriever, dev_questions)\n",
        "test_questions = align_gold_ids(retriever, test_questions)\n",
        "\n",
        "# Write back to JSON files\n",
        "with open(\"dev_set.json\",  \"w\") as f:\n",
        "    json.dump(dev_questions, f, indent=2)\n",
        "with open(\"test_set.json\", \"w\") as f:\n",
        "    json.dump(test_questions, f, indent=2)\n",
        "\n",
        "\n",
        "# 2) Re‐run the evaluation cell now that gold_node_ids have valid IDs.\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# STEP 0: Imports and load dev/test question files\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import util\n",
        "\n",
        "with open(\"dev_set.json\",  \"r\") as f:\n",
        "    dev_questions  = json.load(f)\n",
        "with open(\"test_set.json\", \"r\") as f:\n",
        "    test_questions = json.load(f)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# STEP 1: Helper to compute Recall@K and MRR@K\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def evaluate_retriever(retriever, question_data, K=10):\n",
        "    total = len(question_data)\n",
        "    num_recall_hits = 0\n",
        "    sum_reciprocal_rank = 0.0\n",
        "\n",
        "    for entry in question_data:\n",
        "        q_text  = entry[\"question\"]\n",
        "        gold_ids = set(entry[\"gold_node_ids\"])\n",
        "\n",
        "        qb = QueryBundle(query_str=q_text)\n",
        "        candidates = retriever.retrieve(qb) or []\n",
        "        topk = candidates[:K]\n",
        "\n",
        "        found_rank = None\n",
        "        for rank, node in enumerate(topk, start=1):\n",
        "            if node.node_id in gold_ids:\n",
        "                found_rank = rank\n",
        "                break\n",
        "\n",
        "        if found_rank is not None:\n",
        "            num_recall_hits += 1\n",
        "            sum_reciprocal_rank += 1.0 / found_rank\n",
        "\n",
        "    recall_at_K = num_recall_hits / total\n",
        "    mrr_at_K    = sum_reciprocal_rank / total\n",
        "    return recall_at_K, mrr_at_K\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# STEP 2: Evaluate retriever on dev set\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "dev_recall10, dev_mrr10 = evaluate_retriever(retriever, dev_questions,  K=10)\n",
        "dev_recall20, dev_mrr20 = evaluate_retriever(retriever, dev_questions,  K=20)\n",
        "\n",
        "print(f\"Dev Recall@10 = {dev_recall10:.3f}, MRR@10 = {dev_mrr10:.3f}\")\n",
        "print(f\"Dev Recall@20 = {dev_recall20:.3f}, MRR@20 = {dev_mrr20:.3f}\")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# STEP 3: Hyperparameter grid search on dev\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "best_combination = None\n",
        "best_recall = 0.0\n",
        "\n",
        "for thresh in [0.2, 0.3, 0.4, 0.5, 0.6]:\n",
        "    for boost in [1.0, 1.2, 1.5, 2.0]:\n",
        "        retriever.similarity_threshold = thresh\n",
        "        retriever.boost_factor        = boost\n",
        "        recall10, _ = evaluate_retriever(retriever, dev_questions, K=10)\n",
        "        if recall10 > best_recall:\n",
        "            best_recall      = recall10\n",
        "            best_combination = (thresh, boost)\n",
        "\n",
        "print(\n",
        "    \"Best on dev: threshold =\", best_combination[0],\n",
        "    \"boost =\", best_combination[1],\n",
        "    \"→ Recall@10 =\", best_recall\n",
        ")\n",
        "\n",
        "best_threshold, best_boost = best_combination\n",
        "retriever.similarity_threshold = best_threshold\n",
        "retriever.boost_factor        = best_boost\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "# STEP 4: Compute test‐set retrieval metrics\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "test_recall10, test_mrr10 = evaluate_retriever(retriever, test_questions, K=10)\n",
        "test_recall20, test_mrr20 = evaluate_retriever(retriever, test_questions, K=20)\n",
        "\n",
        "print(f\"Test Recall@10 = {test_recall10:.3f}, MRR@10 = {test_mrr10:.3f}\")\n",
        "print(f\"Test Recall@20 = {test_recall20:.3f}, MRR@20 = {test_mrr20:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNQi5ETyCs_N"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "\n",
        "# Load BLEURT with pre-trained checkpoint\n",
        "bleurt = load(\"bleurt\", checkpoint=\"bleurt-base-512\")\n",
        "\n",
        "# Compute BLEURT scores\n",
        "bleurt_results = bleurt.compute(\n",
        "    predictions=agent_responses,\n",
        "    references=true_answers\n",
        ")\n",
        "\n",
        "# Display average BLEURT score\n",
        "average_bleurt = sum(bleurt_results[\"scores\"]) / len(bleurt_results[\"scores\"])\n",
        "print(f\"✅ Average BLEURT Score: {average_bleurt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBKgRytQ4WEV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Configure Embedding Model ===\n",
        "Settings.embed_model = embed_model\n",
        "Settings.llm = llm\n",
        "\n",
        "# === Load Stored Index ===\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"/content/ANLP_Project/index\")\n",
        "\n",
        "index = load_index_from_storage(storage_context)\n",
        "\n",
        "# Use the boosted retriever\n",
        "retriever = DatasetBoostRetriever(index=index, embed_model=embed_model)\n",
        "\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",  # Use context-based QA mode\n",
        "    memory=ChatMemoryBuffer.from_defaults(token_limit=32000),  # Large memory for longer convos\n",
        "    system_prompt=(\n",
        "        \"You are a biomedical assistant trained to answer questions about COVID-19, \"\n",
        "        \"smoking, and the correlation between the two. You only answer based on the \"\n",
        "        \"context provided through your knowledge base.\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcZuuNrck-iS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.chat_engine import ContextChatEngine\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "\n",
        "# 1. Setup: Boosted Retriever\n",
        "retriever = DatasetBoostRetriever(index=index, embed_model=embed_model)\n",
        "\n",
        "# 2. Build the Chat Engine with the retriever\n",
        "chat_engine = ContextChatEngine.from_defaults(\n",
        "    retriever=retriever,  # ✅ Corrected line\n",
        "    memory=ChatMemoryBuffer.from_defaults(token_limit=32000),\n",
        "    system_prompt=(\n",
        "        \"You are a biomedical assistant trained to answer questions about COVID-19, \"\n",
        "        \"smoking, and the correlation between the two. Only answer based on the \"\n",
        "        \"retrieved context from the knowledge base.\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCmPCxyIhvrp"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "class DatasetBoostRetriever(VectorIndexRetriever):\n",
        "    def _postprocess_nodes(self, nodes, query_bundle):\n",
        "        for node in nodes:\n",
        "            if node.metadata.get(\"is_dataset_linked\"):\n",
        "                node.score *= 1.3  # 🔼 Boost score if dataset-linked\n",
        "        return sorted(nodes, key=lambda n: n.score, reverse=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}